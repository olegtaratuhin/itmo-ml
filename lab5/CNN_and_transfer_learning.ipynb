{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OAqC8xXmZ1Av"
   },
   "source": [
    "## Convolutional Neural Network \"from scratch\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3z8CfGD5Z1Ay"
   },
   "source": [
    "In this notebook you will learn to distinguish dogs from cats!\n",
    "\n",
    "Data:\n",
    "https://drive.google.com/drive/folders/1nzVk4GOvKR6P87uPszUkKMPtaXV_wrZf?usp=sharing\n",
    "\n",
    "Fill all the necessary gaps in cells below and fit neural networks for solving the binary classification task.\n",
    "\n",
    "## Task 1:\n",
    "\n",
    "1. Build and fit CNN with 3 convolutional layers for binary classification\n",
    "2. Evaluate accuracy on test data\n",
    "3. Plot the graphs for Loss(number_of_epochs) and Accuracy(number_of_epochs)\n",
    "\n",
    "First, let's load all the necessary functions:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "HyzNnZpdZ1A4",
    "outputId": "d588b0a5-de6a-426b-dd7e-f01f7ec78992"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D\n",
    "from keras.applications import VGG16\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DS-6t0_XZ1BL"
   },
   "source": [
    "The images collected for training and testing the deep learning model must be prepared: split the entire set into a training, validation and test sample, observing the balancing of classes (with binary classification they should be approximately equal in all three samples).\n",
    "\n",
    "This has _already_ been done: in the Cats_and_Dogs directory there are three subdirectories: train, test and val - training, test and validation samples, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "colab_type": "code",
    "id": "iK6VqL9Abk9v",
    "outputId": "84bfee95-823b-43d2-d895-4526607ffa9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "# if you are using google colab for this task you can mount your GoogleDrive as follows: \n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')\n",
    "\n",
    "# After running this cell you should enter the authorization code from your Google account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ejt0NSnVZ1BP"
   },
   "outputs": [],
   "source": [
    "# Initialize the folders with train, test and validation datasets (in \"/My Drive/...\" or from your local repository where you have downloaded data):\n",
    "\n",
    "train = '/..'\n",
    "val =   '/..'\n",
    "test =  '/..'\n",
    "\n",
    "# The shape of the RGB image\n",
    "img_width, img_height, channels = 150, 150, 3 # you can try different sizes\n",
    "\n",
    "# input shape\n",
    "input_shape = (img_width, img_height, 3)\n",
    "# position matters!\n",
    "# Number_of_channels can be at the first or the last position\n",
    "# in our case - \"channels last\"\n",
    "\n",
    "# batch size\n",
    "batch_size = 64\n",
    "# train set size\n",
    "nb_train_samples = \n",
    "# validation set size \n",
    "nb_validation_samples = \n",
    "# test set size\n",
    "nb_test_samples = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rYe-jLGbZ1Bh"
   },
   "source": [
    "## Prepare the data.\n",
    "\n",
    "You don’t have to manually change the shapes of 25000 images and convert them into the necessary format for keras (img_width, img_height, 3).\n",
    "\n",
    "We will use the built-in image preprocessing function for training deep neural networks _ImageGenerator_.\n",
    "\n",
    "It performs scaling, resizes selected images and prepares batches (mini-samples) to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "Ncx9lh6LZ1Bk",
    "outputId": "74fe1156-17d2-4f45-f589-520a5fc2d0b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 2 classes.\n",
      "Found 2500 images belonging to 2 classes.\n",
      "Found 2500 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    train,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "val_generator = datagen.flow_from_directory(\n",
    "    val,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "test_generator = datagen.flow_from_directory(\n",
    "    test,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MRvSz7oXZ1B2"
   },
   "outputs": [],
   "source": [
    "# use generator for training the model (\"fit\" method analog)\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=10,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GthRQyZHZ1CI"
   },
   "source": [
    "Set the network architecture by sequentially adding layers to it:\n",
    "1. A convolutional layer with 16 neurons, filter size 3x3. Activation function - 'relu'\n",
    "2. MaxPooling layer with filter size 2x2.\n",
    "3. A convolutional layer with 32 neurons, filter size 3x3. Activation function - 'relu'\n",
    "4. MaxPooling layer with filter size 2x2.\n",
    "5. A convolutional layer with 64 neurons, filter size 3x3. Activation function - 'relu'\n",
    "6. MaxPooling layer with filter size 2x2.\n",
    "7. Operation model.add (Flatten ()), which makes a one-dimensional vector of the resulting feature maps.\n",
    "8. A fully connected layer with 64 neurons. Activation function - 'relu'\n",
    "9. Operation model.add (Dropout (0.5)) - excludes a neuron from the current layer with a 50% probability to avoid overfitting. retraining.\n",
    "10. A fully connected layer with 1 neuron. Activation function - 'sigmoid', because binary classification model.\n",
    "\n",
    "Add to the model all the missing layers, by analogy with the already specified.\n",
    "Keras documentation: https://keras.io/layers/about-keras-layers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yNik7qzRZ1CU"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# 1: +Convolutional\n",
    "# For example:\n",
    "model.add(Conv2D(16, (3, 3), input_shape=(150, 150, 3)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# 2: +Pooling\n",
    "# 3:\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "#     +Relu\n",
    "\n",
    "# 4:  +Pooling \n",
    "# 5:  +Convolutional\n",
    "#     +Relu\n",
    "# 6:  +Pooling \n",
    "# 7:  +Flattening\n",
    "# 8:  +Convolutional\n",
    "#     +ReLu\n",
    "# 9:  +Dropout\n",
    "# 10: +Dense\n",
    "#     +Sigmoid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0nNS5cLjZ1Cg"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BzqPxMJdZ1Cu"
   },
   "outputs": [],
   "source": [
    "# use the generator to train the model (analogue of the fit method)\n",
    "# 1 epoch of training on a CPU will take 4-6 minutes. The GPU is an ~order of magnitude faster.\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=, #try different number of epochs: 10, 15, 20; check the loss and accuracy;\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KBMrJqBHZ1DT"
   },
   "outputs": [],
   "source": [
    "scores = model.evaluate_generator(test_generator, nb_test_samples // batch_size)\n",
    "print(\"Accuracy on test data: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mle_LO6XMJ62"
   },
   "source": [
    "Plot the graphs: \n",
    "\n",
    "Loss(Number of epochs)\n",
    "\n",
    "Accuracy(Number of epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b2pVi2vEZ1Dk"
   },
   "source": [
    "![alt text](Deeper.jpeg )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bMceppSCZ1Dq"
   },
   "source": [
    "##  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QESIOnCPZ1Dz"
   },
   "source": [
    "Let's try to improve the quality of recognition, using the method of transfer lerning - \"transfer training.\" \n",
    "\n",
    "We will use weights of deep neural networks already trained on large dataset such as  ImageNet, and provide fine tuning of several additional dense layers on new data relevant to the current classification task. The more new images will differ from those on which the network has been trained, the more layers will need to be “retrained” in order to get good classification accuracy. The intuition here is that the model has already learned how to highlight the necessary features on the images in the large dataset, it only needs to be “tweaked” for a specific task.\n",
    "\n",
    "## Task 2\n",
    "\n",
    "1. Build and fit Transfer Learning model using pre-trained VGG16-model weights from keras application.\n",
    "2. Do the same with another avaliable pre-trained deep learning model from keras application.\n",
    "2. Evaluate accuracy on test data\n",
    "3. Plot the graphs for Loss(number_of_epochs) and Accuracy(number_of_epochs)\n",
    "4. Check the performance of your model with the custom image of cat or dog (so the model will tell which class this image belongs to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Md_9fT-nZ1D2"
   },
   "outputs": [],
   "source": [
    "# First, download the weights of the VGG16 network trained on the ImageNet dataset:\n",
    "\n",
    "vgg16_net = VGG16(weights='imagenet', \n",
    "                  include_top=False,      # we take only the \"convolution\" part, the last layers we add ourselves\n",
    "                  input_shape=(150, 150, 3))\n",
    "vgg16_net.trainable = False               # clearly prescribe that we do NOT overload the network.\n",
    "                                          # Weights VGG16 in the process of learning will remain unchanged!\n",
    "\n",
    "vgg16_net.summary()                       # pay attention to the number of trained and untrained parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a_DTDXqWZ1EG"
   },
   "source": [
    "We construct our model of \"transfer learning\" by adding two fully connected layers to VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hKYlhGqTZ1EJ"
   },
   "outputs": [],
   "source": [
    "# add layers to VGG16:\n",
    "\n",
    "model = Sequential()\n",
    "model.add(vgg16_net)\n",
    "\n",
    "# + flattening\n",
    "# + dense connected layer with 256 neurons\n",
    "# + ReLu\n",
    "# + Dropout\n",
    "# + full layer with 1 neuron\n",
    "# + sigmoid\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hKU1pQEeZ1Ea"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=Adam(lr=1e-5), \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZxBZMbzAZ1Ex"
   },
   "source": [
    "E.g., it was like:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CW-eEROdZ1FK"
   },
   "source": [
    "![alt text](VGG16.png )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XAPd3c7SZ1FP"
   },
   "source": [
    "and it becomes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9poV5PlvZ1FT"
   },
   "source": [
    "![alt text](VGG162.png )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gNX7L-MIZ1FX"
   },
   "outputs": [],
   "source": [
    "# We also use the generator to train the model (similar to the fit method)\n",
    "# Without using a GPU, learning 1 epoch of such a network will take about an hour. Plan your time =)\n",
    "# If you have access to a GPU, you can try 10-12 epochs - the quality should increase even more.\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=5,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vMCxq21YZ1Fh"
   },
   "outputs": [],
   "source": [
    "scores = model.evaluate_generator(test_generator, nb_test_samples // batch_size)\n",
    "print(\"Accuracy on test data: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X91KUBWLiEmw"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lab 5 (CNN) and Lab 6 (transfer learning).ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
