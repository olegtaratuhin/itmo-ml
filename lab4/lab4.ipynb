{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "\n",
    "**Description**\n",
    "\n",
    "Download Alice in Wonderland by Lewis Carrol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice corpus have 168183 chars\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "\n",
    "filename = f\"../data/Alice-in-Wonderland.txt\"\n",
    "alice_is_downloaded = os.path.isfile(filename)\n",
    "if not alice_is_downloaded:\n",
    "    from urllib import request\n",
    "\n",
    "    url = \"http://www.gutenberg.org/files/11/11-0.txt\"\n",
    "    request.urlretrieve(url, filename)\n",
    "\n",
    "with open(filename, \"r\") as f:\n",
    "    alice_corpus = ' '.join(f.readlines())\n",
    "\n",
    "print(f\"Alice corpus have {len(alice_corpus)} chars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "\n",
    "**Description**\n",
    "\n",
    "Perform any necessary preprocessing on the test, including converting to lower case, removing stop words, number / non-alphabetic characters and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "spacy.prefer_gpu()\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Process chapters into individual documents**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "chapter_content = dict()\n",
    "\n",
    "chapter_names = {\n",
    "    \"I\": \"Down the Rabbit-Hole\",\n",
    "    \"II\": \"The Pool of Tears\",\n",
    "    \"III\": \"A Caucus-Race and a Long Tale\",\n",
    "    \"IV\": \"The Rabbit Sends in a Little Bill\",\n",
    "    \"V\": \"Advice from a Caterpillar\",\n",
    "    \"VI\": \"Pig and Pepper\",\n",
    "    \"VII\": \"A Mad Tea-Party\",\n",
    "    \"VIII\": \"The Queen’s Croquet-Ground\",\n",
    "    \"IX\": \"The Mock Turtle’s Story\",\n",
    "    \"X\": \"The Lobster Quadrille\",\n",
    "    \"XI\": \"Who Stole the Tarts?\",\n",
    "    \"XII\": \"Alice’s Evidence\"\n",
    "}\n",
    "chapter_numbers = [\"I\", \"II\", \"III\", \"IV\", \"V\", \"VI\", \"VII\", \"VIII\", \"IX\", \"X\", \"XI\", \"XII\"]\n",
    "\n",
    "chapter_beginnings = {\n",
    "    \"I\": \"Alice was beginning to get very tired of sitting by her sister on the\",\n",
    "    \"II\": \"“Curiouser and curiouser!” cried Alice (she was so much surprised, that\",\n",
    "    \"III\": \"They were indeed a queer-looking party that assembled on the bank—the\",\n",
    "    \"IV\": \"It was the White Rabbit, trotting slowly back again, and looking\",\n",
    "    \"V\": \"The Caterpillar and Alice looked at each other for some time in\",\n",
    "    \"VI\": \"For a minute or two she stood looking at the house, and wondering what\",\n",
    "    \"VII\": \"There was a table set out under a tree in front of the house, and the\",\n",
    "    \"VIII\": \"A large rose-tree stood near the entrance of the garden: the roses\",\n",
    "    \"IX\": \"“You can’t think how glad I am to see you again, you dear old thing!”\",\n",
    "    \"X\": \"The Mock Turtle sighed deeply, and drew the back of one flapper across\",\n",
    "    \"XI\": \"The King and Queen of Hearts were seated on their throne when they\",\n",
    "    \"XII\": \"“Here!” cried Alice, quite forgetting in the flurry of the moment how\"\n",
    "}\n",
    "# chapter_beginnings = {k: v.lower() for k, v in chapter_beginnings.items()}\n",
    "\n",
    "def find_start_of_next_chapter(corpus, current_pos=0, last_chapter=None):\n",
    "    if last_chapter:\n",
    "        return alice_corpus.find(chapter_beginnings[chapter_names[0]])\n",
    "    else:\n",
    "        return alice_corpus.find(chapter_beginnings[last_chapter + 1], current_pos)\n",
    "\n",
    "def preprocess_chapter(chapter):\n",
    "    return chapter.lower().replace(\"\\n\", \" \")\n",
    "\n",
    "prev_chapter_start = None\n",
    "for i, number in enumerate(chapter_numbers):\n",
    "    next_chapter_start = alice_corpus.find(chapter_beginnings[number])\n",
    "    if prev_chapter_start is not None:\n",
    "        chapter_content[chapter_numbers[i - 1]] = \\\n",
    "                preprocess_chapter(alice_corpus[prev_chapter_start:next_chapter_start])\n",
    "    prev_chapter_start = next_chapter_start\n",
    "\n",
    "chapter_content[chapter_numbers[-1]] = preprocess_chapter(alice_corpus[prev_chapter_start:alice_corpus.find(\"THE END\")])\n",
    "\n",
    "chapter_doc = { k:nlp(v) for k, v in chapter_content.items() }\n",
    "alice_doc = nlp('\\n'.join(chapter_content.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove stop words, punctuation, non-words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def filter_stopwords(token):\n",
    "    return nlp.vocab[token.text].is_stop\n",
    "\n",
    "def filter_non_alpdabetic(token):\n",
    "    return not nlp.vocab[token.text].is_alpha\n",
    "\n",
    "def filter_punkt(token):\n",
    "    return nlp.vocab[token.text].is_punct\n",
    "\n",
    "def filter_space(token):\n",
    "    return nlp.vocab[token.text].is_space\n",
    "\n",
    "filters = [\n",
    "    filter_stopwords,\n",
    "    filter_non_alpdabetic,\n",
    "    filter_punkt,\n",
    "    filter_space\n",
    "]\n",
    "\n",
    "def apply_filters(token):\n",
    "    for f in filters:\n",
    "        if f(token):\n",
    "            return None\n",
    "    return token\n",
    "\n",
    "def filter_doc(doc):\n",
    "    filtered_doc = []\n",
    "    for token in doc:\n",
    "        if apply_filters(token) is not None:\n",
    "            filtered_doc.append(token)\n",
    "    return filtered_doc\n",
    "\n",
    "def lemmatize(doc):\n",
    "    return [token.lemma_ for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "filtered_chapter_doc = { k: filter_doc(v) for k, v in chapter_doc.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_chapter_doc = { k: ' '.join(lemmatize(v)) for k, v in filtered_chapter_doc.items() }\n",
    "\n",
    "preprocessed_corpus = ' '.join(preprocessed_chapter_doc.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task 3\n",
    "\n",
    "**Description**\n",
    "\n",
    "Find top 10 most important words (TF-IDF, for instance) from each chapter in the text (not \"Alice\"). How would you name each chapter according to the identified tokens?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Get normalized TF-IDF scores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "import pandas as pd\n",
    "\n",
    "cvect = CountVectorizer()\n",
    "counts = cvect.fit_transform(preprocessed_chapter_doc.values())\n",
    "normalized_counts = normalize(counts, norm='l1', axis=1)\n",
    "\n",
    "tfidf = TfidfVectorizer(smooth_idf=False)\n",
    "tfs = tfidf.fit_transform(preprocessed_chapter_doc.values())\n",
    "new_tfs = normalized_counts.multiply(tfidf.idf_)\n",
    "\n",
    "feature_names = tfidf.get_feature_names()\n",
    "corpus_index = [n for n in preprocessed_corpus]\n",
    "df = pd.DataFrame(new_tfs.T.todense(), index=feature_names, columns=chapter_numbers)\n",
    "# df = pd.DataFrame(new_tfs.T.todense(), index=feature_names, columns=corpus_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract most important ones for each capter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_most_important_words_in_chapter(chapter, df):\n",
    "    most_important = filter(lambda x: x != 'alice', list(df[chapter].sort_values(ascending=False)[:11].index))\n",
    "    return list(most_important)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for chapter in chapter_numbers:\n",
    "    print(f\"Chapter {chapter} - \\t {get_most_important_words_in_chapter(chapter, df)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Actual chapter names**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for number, name in chapter_names.items():\n",
    "    print(f\"Chapter {number}: \\t{name}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Actually the names are pretty reasonable, often in fiction chapter names do not reflect chapter's content, which is not suprising: chapter name is probably one of the first things the reader sees when opens a new chapter, he/she should be intrigued by the name, and it probably should not reflect all of the chapter essence in a few words as it may reduce reader's engagement."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Task 4\n",
    "\n",
    "**Description**\n",
    "\n",
    "Find the top 10 most used verbs in sentences with Alice. What does Alice do most often?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Iterate over sentence and collect verbs that has alice as subject**\n",
    "\n",
    "The following counters only take into account sentences where Alice is named explicitly, implicit names are a lot harder to resolve, but perhaps that doesn't change the results as much"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def span_contains(key, sentence):\n",
    "    for word in sentence:\n",
    "        if key == word.text:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "verbs_count = defaultdict(int)\n",
    "verbs_alice_as_subject = defaultdict(int)\n",
    "\n",
    "alice = alice_doc[0]\n",
    "for sentence in alice_doc.sents:\n",
    "    if not span_contains(alice.text, sentence):\n",
    "        continue\n",
    "    \n",
    "    for word in sentence:\n",
    "        if word.pos_ != \"VERB\":\n",
    "            continue\n",
    "        verbs_count[word.text] += 1\n",
    "            \n",
    "        if span_contains(alice.text, list(word.children)):\n",
    "            verbs_alice_as_subject[word.text] += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_top_verbs(counter, k=10):\n",
    "    top = list()\n",
    "    for w in sorted(counter, key=counter.get, reverse=True)[:k]:\n",
    "        top.append(w)\n",
    "    return top"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Simple counter results**\n",
    "\n",
    "Simple counter has all verbs in sentences which word alice appears in."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "get_top_verbs(verbs_count)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Language-aware counter results**\n",
    "\n",
    "More compicated counter takes into account only words that have Alice as a dependency (as a subject). That results in \"more correct\" words being choosen "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "get_top_verbs(verbs_alice_as_subject)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Seems like Alice is doing a lot of talking and thinking, which is probably a good thing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chapter I - \t ['eat', 'fall', 'think', 'bat', 'little', 'key', 'door', 'find', 'go', 'way']\n",
      "Chapter II - \t ['mouse', 'swam', 'little', 'say', 'oh', 'cat', 'pool', 'cry', 'fan', 'mabel']\n",
      "Chapter III - \t ['say', 'mouse', 'dodo', 'prize', 'lory', 'dry', 'race', 'thimble', 'know', 'bird']\n",
      "Chapter IV - \t ['window', 'puppy', 'bill', 'little', 'rabbit', 'fan', 'grow', 'say', 'glove', 'bottle']\n",
      "Chapter V - \t ['caterpillar', 'say', 'serpent', 'pigeon', 'youth', 'egg', 'size', 'father', 'think', 'hookah']\n",
      "Chapter VI - \t ['footman', 'say', 'cat', 'baby', 'mad', 'duchess', 'grin', 'wow', 'grunt', 'go']\n",
      "Chapter VII - \t ['hatter', 'dormouse', 'say', 'hare', 'march', 'twinkle', 'tea', 'time', 'remark', 'treacle']\n",
      "Chapter VIII - \t ['queen', 'say', 'hedgehog', 'king', 'gardener', 'rose', 'soldier', 'go', 'look', 'executioner']\n",
      "Chapter IX - \t ['say', 'turtle', 'mock', 'gryphon', 'moral', 'duchess', 'queen', 'go', 'think', 'school']\n",
      "Chapter X - \t ['turtle', 'gryphon', 'mock', 'dance', 'say', 'lobster', 'soup', 'whiting', 'beautiful', 'oop']\n",
      "Chapter XI - \t ['king', 'hatter', 'court', 'say', 'dormouse', 'witness', 'juror', 'officer', 'jury', 'queen']\n",
      "Chapter XII - \t ['say', 'king', 'jury', 'dream', 'write', 'queen', 'sister', 'slate', 'juryman', 'important']\n"
     ]
    }
   ],
   "source": [
    "### Task 5\n",
    "\n",
    "**Description**\n",
    "\n",
    "Find the top 100 most used verbs in sentences with Alice. Get word2vec visualization of them. Compare word embeddings and write conclusions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Actual chapter names**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chapter I: \tDown the Rabbit-Hole\n",
      "Chapter II: \tThe Pool of Tears\n",
      "Chapter III: \tA Caucus-Race and a Long Tale\n",
      "Chapter IV: \tThe Rabbit Sends in a Little Bill\n",
      "Chapter V: \tAdvice from a Caterpillar\n",
      "Chapter VI: \tPig and Pepper\n",
      "Chapter VII: \tA Mad Tea-Party\n",
      "Chapter VIII: \tThe Queen’s Croquet-Ground\n",
      "Chapter IX: \tThe Mock Turtle’s Story\n",
      "Chapter X: \tThe Lobster Quadrille\n",
      "Chapter XI: \tWho Stole the Tarts?\n",
      "Chapter XII: \tAlice’s Evidence\n"
     ]
    }
   ],
   "source": [
    "for number, name in chapter_names.items():\n",
    "    print(f\"Chapter {number}: \\t{name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually the names are pretty reasonable, often in fiction chapter names do not reflect chapter's content, which is not suprising: chapter name is probably one of the first things the reader sees when opens a new chapter, he/she should be intrigued by the name, and it probably should not reflect all of the chapter essence in a few words as it may reduce reader's engagement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4\n",
    "\n",
    "**Description**\n",
    "\n",
    "Find the top 10 most used verbs in sentences with Alice. What does Alice do most often?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Iterate over sentence and collect verbs that has alice as subject**\n",
    "\n",
    "The following counters only take into account sentences where Alice is named explicitly, implicit names are a lot harder to resolve, but perhaps that doesn't change the results as much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def span_contains(key, sentence):\n",
    "    for word in sentence:\n",
    "        if key == word.text:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "verbs_count = defaultdict(int)\n",
    "verbs_alice_as_subject = defaultdict(int)\n",
    "\n",
    "alice = alice_doc[0]\n",
    "for sentence in alice_doc.sents:\n",
    "    if not span_contains(alice.text, sentence):\n",
    "        continue\n",
    "    \n",
    "    for word in sentence:\n",
    "        if word.pos_ != \"VERB\":\n",
    "            continue\n",
    "        verbs_count[word.text] += 1\n",
    "            \n",
    "        if span_contains(alice.text, list(word.children)):\n",
    "            verbs_alice_as_subject[word.text] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_verbs(counter, k=10):\n",
    "    top = list()\n",
    "    for w in sorted(counter, key=counter.get, reverse=True)[:k]:\n",
    "        top.append(w)\n",
    "    return top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Simple counter results**\n",
    "\n",
    "Simple counter has all verbs in sentences which word alice appears in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['said',\n",
       " 'thought',\n",
       " 'could',\n",
       " 'would',\n",
       " 'went',\n",
       " '’s',\n",
       " 'looked',\n",
       " 'began',\n",
       " 'think',\n",
       " 'see']"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_verbs(verbs_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Language-aware counter results**\n",
    "\n",
    "More compicated counter takes into account only words that have Alice as a dependency (as a subject). That results in \"more correct\" words being choosen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['said',\n",
       " 'thought',\n",
       " 'replied',\n",
       " 'began',\n",
       " 'went',\n",
       " 'looked',\n",
       " 'felt',\n",
       " 'cried',\n",
       " 'heard',\n",
       " 'asked']"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_verbs(verbs_alice_as_subject)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like Alice is doing a lot of talking and thinking, which is probably a good thing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5\n",
    "\n",
    "**Description**\n",
    "\n",
    "Find the top 100 most used verbs in sentences with Alice. Get word2vec visualization of them. Compare word embeddings and write conclusions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}